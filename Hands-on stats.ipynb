{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### MEANS (ARITHMETIC, GEOMETRIC AND HARMONIC) WEIGHTED MEAN and MEDIAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weight can be from domain knowledge, number of occurence, penalty factor, aggregattion etc, depends on the context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://corporatefinanceinstitute.com/resources/knowledge/other/weighted-mean/\n",
    "#https://machinelearningmastery.com/arithmetic-geometric-and-harmonic-means-for-machine-learning/#:~:text=The%20arithmetic%20mean%20is%20appropriate,with%20different%20measures%2C%20called%20rates.\n",
    "#https://www.linkedin.com/pulse/20140715160509-29681087-median-vs-average-household-income/\n",
    "#https://towardsdatascience.com/on-average-youre-using-the-wrong-average-geometric-harmonic-means-in-data-analysis-2a703e21ea0\n",
    "#https://jlmc.medium.com/understanding-three-simple-statistics-for-data-visualizations-2619dbb3677a\n",
    "#https://medium.com/towards-artificial-intelligence/geometric-mean-classifier-for-iris-dataset-ed83209f54f3\n",
    "\n",
    "#It is important to note that all the probabilities or weights must be mutually exclusive \n",
    "#(i.e., no two events can occur at the same time) and that the total weights and probabilities must add up to 100%.\n",
    "\n",
    "#When calculating an arithmetic mean, we make the assumption that all numbers used in the calculation show an equal probability of occurring or have equal weights. Thus, we do not need to account for the differences and can simply sum up the numbers that we are interested in finding the mean of and then dividing the sum by the number of observations.\n",
    "\n",
    "# NOTE\n",
    "# accounting for uncertainty lies\n",
    "# at the heart of the discipline of statistics, whereas concrete business or organizational\n",
    "# objectives are the focus of data science. Hence, statisticians estimate, and data scientists\n",
    "# measure.\n",
    "#At the heart of statistics lies variability:\n",
    "#measuring it, reducing it, distinguishing random from real variability, identifying\n",
    "#the various sources of real variability, and making decisions in the presence of it.\n",
    "\n",
    "\n",
    "#MEAN,\n",
    "#AM>TRIMMED_MEAN>MEDIAN\n",
    "#AM > GM > HM\n",
    "\n",
    "#variance\n",
    "#SD>Mean_abs_dev>Median_abs_dev_from_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(0.25*0.30 - 0.12*0.45 + 0.04*0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"class\":[\"A\",\"B\",\"C\"],\"value\":[50,60,70],\"weight\":[3,2,1]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import robustats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robustats.weighted_median(df[\"value\"],df[\"weight\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted.median(df[\"value\"],df[\"weight\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### SUMMARIZING WITH GROUPBY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/pandas-groupby-aggregate-transform-filter-c95ba3444bbb\n",
    "#https://towardsdatascience.com/using-pandas-transform-and-apply-to-deal-with-missing-data-on-a-group-level-cb6ccf060531\n",
    "#https://towardsdatascience.com/11-examples-to-master-pandas-groupby-function-86e0de574f38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_leads = pd.read_csv(\n",
    "    'https://raw.githubusercontent.com/FBosler/Medium-Data-Exploration/master/order_leads.csv',\n",
    "    parse_dates = [3]\n",
    ")\n",
    "sales_team = pd.read_csv(\n",
    "    'https://raw.githubusercontent.com/FBosler/Medium-Data-Exploration/master/sales_team.csv',\n",
    "    parse_dates = [3]\n",
    ")\n",
    "df = pd.merge(order_leads,sales_team,on=['Company Id','Company Name'])\n",
    "df = df.rename(columns={'Order Value':'Val','Converted':'Sale'})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(df['Sales Rep'].str.split(' ').str[0]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(df['Sales Rep'].apply(lambda x: 'William' in x)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(pd.qcut(x=df['Val'],q=3,labels=['low','mid','high'])).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.lineplot(x=\"Date\",y=\"count\",data = df.groupby(pd.Grouper(key='Date',freq='Q')).size().reset_index().rename(columns = {0:\"count\"}));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouped = df.groupby('GROUP') and then:\n",
    "# - group.apply(mean)\n",
    "# - group.agg(mean)\n",
    "# - group['INTERSTING COLUMN'].apply(mean)\n",
    "# - group.agg({'INTERSTING COLUMN':mean})\n",
    "# - group.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##groupby percentage missing\n",
    "test_df = pd.DataFrame({\"class\":[\"A\",\"A\",\"B\",\"B\"],\"value\":[np.nan,1,np.nan,np.nan]})\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.groupby(\"class\")[\"value\"].apply(lambda x:x.isna().mean())\n",
    "test_df.groupby(\"class\")[\"value\"].apply(lambda x:x.count()/x.shape[0])\n",
    "##NOTE : size is including missing, count does not count missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.groupby(\"class\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cr(x):\n",
    "    return round(np.mean(x),2)\n",
    "# Long Form: Explictly specifying the NamedAgg\n",
    "aggregation = {\n",
    "    'Potential Sales': pd.NamedAgg(column='Val', aggfunc='size'),\n",
    "    'Sales': pd.NamedAgg(column='Sale', aggfunc='sum'),\n",
    "    'Conversion Rate': pd.NamedAgg(column='Sale', aggfunc=cr)\n",
    "}\n",
    "# Alternative: Since the NamedAgg is just a tuple, we can also pass regular tuples\n",
    "# aggregation = {\n",
    "#     'Potential Sales': ('Val','size'),\n",
    "#     'Sales': ('Sale','sum'),\n",
    "#     'Conversion Rate': ('Sale',cr)\n",
    "# }\n",
    "df.groupby('Sales Rep').agg(**aggregation) #NOTE: without double star it wont work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unlike agg, transform is typically used by assigning the results to a new column.\n",
    "df.groupby('Sales Rep')['Val'].transform(lambda x: x/sum(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Sales Rep').filter(lambda x: (x['Val'] * x['Sale']).sum() > 200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Sales Rep')[\"Date\"].apply(lambda x:x.sort_values()).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df.groupby(\"Sales Rep\").agg(\n",
    "    {\"Val\": [(\"max_Sale\",\"max\"), (\"mean_Val\",\"mean\")]}).reset_index()\n",
    "\n",
    "test.columns = test.columns.droplevel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### why n-1 instead of n for sample variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.youtube.com/watch?v=D1hgiAla3KI ##proof\n",
    "#https://www.youtube.com/watch?v=M1bR2uK5jUc\n",
    "#https://towardsdatascience.com/why-sample-variance-is-divided-by-n-1-89821b83ef6d\n",
    "\n",
    "##as sample mean is used(which is biased)sample variance is always underestimated when divided by n,to make an adjustment,n-1 is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=[1,2,3,4,5,4.5,6,3.5,6,7,3.4,8,2.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = [4,5,4.5,6,6.5]\n",
    "s2 = [1.2,1.3,1.5,6,2.5]\n",
    "s3 = [1.2,1.3,1.5,6,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm1=np.mean(s1)\n",
    "sv1=np.std(s1)\n",
    "print(sm1)\n",
    "print(sv1)\n",
    "\n",
    "sm2=np.mean(s2)\n",
    "sv2=np.std(s2)\n",
    "print(sm2)\n",
    "print(sv2)\n",
    "\n",
    "sm3=np.mean(s3)\n",
    "sv3=np.std(s3)\n",
    "print(sm3)\n",
    "print(sv3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm=np.mean(p)\n",
    "pv=np.std(p)\n",
    "print(pm)\n",
    "print(pv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.quantile(s1,0.85) #in small samples, quantile might imagine a ditribution to calculate a percentile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### CORRELATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/rip-correlation-introducing-the-predictive-power-score-3d90808b9598\n",
    "# https://towardsdatascience.com/the-search-for-categorical-correlation-a1cf7f1888c9\n",
    "#https://towardsdatascience.com/the-best-classification-metric-youve-never-heard-of-the-matthews-correlation-coefficient-3bf50a2f3e9a\n",
    "#https://www.kaggle.com/shakedzy/alone-in-the-woods-using-theil-s-u-for-survival\n",
    "#https://medium.com/@outside2SDs/an-overview-of-correlation-measures-between-categorical-and-continuous-variables-4c7f85610365\n",
    "\n",
    "#Predicting rare events with certainty is incredibly difficult."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### EDA HANDS-ON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sns.load_dataset(\"penguins\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"island\",\"species\",\"sex\"]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"species\",\"island\"])[\"bill_length_mm\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"species\",\"island\"]).transform(lambda x:x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ki=KNNImputer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed_num = pd.DataFrame(ki.fit_transform(df[[\"bill_length_mm\",\"bill_depth_mm\",\"flipper_length_mm\",\"body_mass_g\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ki.fit_transform(df[\"sex\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = pd.to_datetime(\"2020-02-14\")\n",
    "snapshot_date = date + pd.Timedelta(days = 1)\n",
    "snapshot_week = snapshot_date.week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot_date.week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### INSTALLING PACKAGE FROM GIT WITH SETUP.PY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##clone the repo, from pwd, run python setup.py install to install the package\n",
    "from feature_selector import FeatureSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_object=LogisticRegression()\n",
    "custom_grid ={'penalty': [\"l2\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_train = np.array([1,2,3,4,5]).reshape(-1,1)\n",
    "Y_train = np.array([1,0,1,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcv=GridSearchCV(model_object,param_grid=custom_grid,\n",
    "                                 scoring = \"r2\",cv=2)\n",
    "grid_result = gcv.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_result.cv_results_[\"mean_test_score\"][0])\n",
    "print(grid_result.cv_results_[\"std_test_score\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sample_package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"C:\\\\HANDS-ON\\\\CREATE_PACKAGE_PUSH_GIT\\\\sample_package\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sample_package.folder1.file1 import function1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting function1\n"
     ]
    }
   ],
   "source": [
    "function1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
